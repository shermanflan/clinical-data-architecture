version: "3.8"
services:
  pgsql-spark:
    image: postgres:11
    ports:
        - 5432:5432
    environment:
        - POSTGRES_USER=sa
        - POSTGRES_PASSWORD=pwd
        - POSTGRES_DB=psycodb
  stage_data:
    image: stage_data
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - 4040:4040
      - 10000:10000
    command: [
      "/bin/sh",
      "-c",
      "/opt/spark/bin/spark-submit \
      --name stage_data \
      --conf spark.jars.packages=io.delta:delta-core_2.12:1.0.0 \
      local:///opt/spark/stage_data/main.py \
      staging \
      --filepath s3a://bangkok/departuredelays.csv
      --output_path s3a://condesa/departuredelays"
    ]
    depends_on:
      - pgsql-spark
    env_file: .env
    environment:
      - LOG_LEVEL=INFO
      - SPARK_LOG_LEVEL=WARN
      - POSTGRES_DB_URL=postgresql://sa:pwd@pgsql-spark/psycodb
      - POSTGRES_JDBC_URL=jdbc:postgresql://pgsql-spark/psycodb?user=sa&password=pwd
    volumes:
      - ./local_config:/opt/spark/conf
      # - ./local_hive:/opt/spark/hive_warehouse
      - ./sample_data/synthea_1m_fhir_3_0_May_24/output_1/csv:/opt/spark/work-dir/sample_data/output_1
      - ./sample_data/synthea_1m_fhir_3_0_May_24/output_2/csv:/opt/spark/work-dir/sample_data/output_2
      - ./sample_data/output_data:/opt/spark/work-dir/output_data
