{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d0007e5",
   "metadata": {},
   "source": [
    "# Data Pipeline using PySpark/Delta Lake\n",
    "Uses publicly available geography data sets.\n",
    "\n",
    "References:\n",
    "- [Geonames zipcodes](http://download.geonames.org/export/zip/)\n",
    "- [US Gazetteer](https://www.usgs.gov/core-science-systems/ngp/board-on-geographic-names/download-gnis-data)\n",
    "- [US Gazetteer Spec](https://geonames.usgs.gov/docs/pubs/Nat_State_Topic_File_formats.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be5b877",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "ls /opt/spark/jupyter-lib/input_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc76dfd",
   "metadata": {},
   "source": [
    "## Build Spark session with Delta Table bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d85e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .appName(\"example-3-geonames\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.12:1.0.0\")\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\",\n",
    "            \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    # S3A Optimizations\n",
    "    .config(\"spark.hadoop.mapreduce.fileoutputcommitter.algorithm.version\", \"2\")\n",
    "    .config(\"spark.hadoop.mapreduce.fileoutputcommitter.cleanup-failures.ignored\", \"true\")\n",
    "    # TODO: S3A Optimizations: PathOutputCommitProtocol cannot be resolved\n",
    "#     .config(\"spark.hadoop.fs.s3a.committer.name\", \"directory\")\n",
    "#     .config(\"spark.sql.sources.commitProtocolClass\",\n",
    "#             \"org.apache.spark.internal.io.cloud.PathOutputCommitProtocol\")\n",
    "#     .config(\"spark.sql.parquet.output.committer.class\",\n",
    "#             \"org.apache.spark.internal.io.cloud.BindingParquetOutputCommitter\")\n",
    "    # Parquet Optimizations\n",
    "    .config(\"spark.hadoop.parquet.enable.summary-metadata\", \"false\")\n",
    "    .config(\"spark.sql.parquet.mergeSchema\", \"false\")\n",
    "    .config(\"spark.sql.parquet.filterPushdown\", \"true\")\n",
    "    .config(\"spark.sql.hive.metastorePartitionPruning\", \"true\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34277b79",
   "metadata": {},
   "source": [
    "### Setup Data Lake paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3\n",
    "zipcode_raw_path = 's3a://condesa/input_data/geonames/'\n",
    "geography_raw_path = 's3a://condesa/input_data/gazetteer/'\n",
    "output_root_path = 's3a://condesa/output_data'\n",
    "\n",
    "# Local\n",
    "# zipcode_raw_path = '/opt/spark/work-dir/input_data/geonames/'\n",
    "# geography_raw_path = '/opt/spark/work-dir/input_data/gazetteer/'\n",
    "# output_root_path = '/opt/spark/work-dir/output_data'\n",
    "\n",
    "zipcode_path = (\n",
    "    \"{root}/stage/zipcode/parquet/{Y}/{M:02d}/{D:02d}\"\n",
    "    .format(root=output_root_path,\n",
    "            Y=date.today().year,\n",
    "            M=date.today().month,\n",
    "            D=date.today().day)\n",
    ")\n",
    "geography_path = (\n",
    "    \"{root}/stage/geography/parquet/{Y}/{M:02d}/{D:02d}\"\n",
    "    .format(root=output_root_path,\n",
    "            Y=date.today().year,\n",
    "            M=date.today().month,\n",
    "            D=date.today().day)\n",
    ")\n",
    "delta_path = (\n",
    "    \"{root}/public/geography/delta\"\n",
    "    .format(root=output_root_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece7d275",
   "metadata": {},
   "source": [
    "## Define Input Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b33d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEONAMES = \"\"\"\n",
    "    country_code STRING,\n",
    "    postal_code  STRING,\n",
    "    place_name   STRING,\n",
    "    admin_name1  STRING,  -- order subdivision (state)\n",
    "    admin_code1  STRING,\n",
    "    admin_name2  STRING,  -- order subdivision (county/province)\n",
    "    admin_code2  STRING,\n",
    "    admin_name3  STRING,  -- order subdivision (community)\n",
    "    admin_code3  STRING,\n",
    "    latitude     DECIMAL(12, 2),\n",
    "    longitude    DECIMAL(12, 2),\n",
    "    -- of lat/lng: 1=estimated, 4=geonameid, 6=centroid of addresses or shape\n",
    "    accuracy     INT\n",
    "\"\"\"\n",
    "\n",
    "GAZETTEER = \"\"\"\n",
    "    feature_id      INT,\n",
    "    feature_name    STRING,\n",
    "    feature_class   STRING,\n",
    "    state_alpha     STRING,\n",
    "    state_numeric   STRING,\n",
    "    county_name     STRING,\n",
    "    county_numeric  STRING,\n",
    "    primary_lat_dms STRING,\n",
    "    prim_long_dms   STRING,\n",
    "    prim_lat_dec    DECIMAL(12, 2),\n",
    "    prim_long_dec   DECIMAL(12, 2),\n",
    "    source_lat_dms  STRING,\n",
    "    source_long_dms STRING,\n",
    "    source_lat_dec  DECIMAL(12, 2),\n",
    "    source_long_dec DECIMAL(12, 2),\n",
    "    elev_in_m       INT,\n",
    "    elev_in_ft      INT,\n",
    "    map_name        STRING,\n",
    "    date_created    DATE,\n",
    "    date_edited     DATE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a2c2b",
   "metadata": {},
   "source": [
    "## Read zipcodes CSV into DataFrame\n",
    "TODO:\n",
    "- Pick a specific file within a ZIP archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab37cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "zipcode = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(\n",
    "        path=zipcode_raw_path,\n",
    "        schema=GEONAMES,\n",
    "        sep=\"\\t\",\n",
    "        header=False\n",
    "    )\n",
    "    .withColumnRenamed('admin_name1', 'state_name')\n",
    "    .withColumnRenamed('admin_code1', 'state_code')\n",
    "    .withColumnRenamed('admin_name2', 'county_name')\n",
    "    .withColumnRenamed('admin_code2', 'county_code')\n",
    "    .drop('accuracy', 'admin_name3', 'admin_code3')\n",
    "    .filter(col('state_code').isNotNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803c7f9",
   "metadata": {},
   "source": [
    "## Read Gazetteer geographies from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df1682",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geography = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(\n",
    "        path=geography_raw_path,\n",
    "        schema=GAZETTEER,\n",
    "        sep=\"|\",\n",
    "        dateFormat=\"MM/dd/yyyy\",\n",
    "        mode=\"FAILFAST\",\n",
    "        header=True\n",
    "    )\n",
    "    .withColumnRenamed('state_alpha', 'state_code')\n",
    "    .withColumnRenamed('county_numeric', 'county_code')\n",
    "    .withColumnRenamed('prim_lat_dec', 'latitude')\n",
    "    .withColumnRenamed('prim_long_dec', 'longitude')\n",
    "    .drop('state_numeric', \n",
    "          'primary_lat_DMS', 'prim_long_dms',\n",
    "          'source_lat_dms', 'source_long_dms', \n",
    "          'source_lat_dec', 'source_long_dec',\n",
    "          'elev_in_ft', 'date_edited'\n",
    "         )\n",
    "    .filter(col('state_code').isNotNull())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2e5c9a",
   "metadata": {},
   "source": [
    "## Stage unrefined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949f245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    zipcode\n",
    "    .write\n",
    "    .parquet(\n",
    "        zipcode_path,\n",
    "        mode='overwrite',\n",
    "        partitionBy='state_code'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0644269",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    geography\n",
    "    .write\n",
    "    .parquet(\n",
    "        geography_path,\n",
    "        mode='overwrite',\n",
    "        partitionBy='state_code'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7650fe",
   "metadata": {},
   "source": [
    "## Transform data\n",
    "Join geographies to zipcodes on place name, county, and state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9ff3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format('parquet')\n",
    "    .load(zipcode_path)\n",
    "    .createOrReplaceTempView('vw_zipcode')\n",
    ")\n",
    "(\n",
    "    spark\n",
    "    .read\n",
    "    .format('parquet')\n",
    "    .load(geography_path)\n",
    "    .createOrReplaceTempView('vw_geography')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18951c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geography_conformed = spark.sql(\"\"\"\n",
    "    SELECT  g.feature_id,\n",
    "            g.feature_name AS place_name,\n",
    "            g.county_name,\n",
    "            g.county_code,\n",
    "            g.state_code,\n",
    "            zip.postal_code,\n",
    "            g.latitude,\n",
    "            g.longitude,\n",
    "            g.elev_in_m,\n",
    "            g.map_name,\n",
    "            g.date_created\n",
    "    FROM    vw_geography AS g\n",
    "        INNER JOIN vw_zipcode AS zip\n",
    "            ON g.feature_name = zip.place_name\n",
    "                AND g.county_code = zip.county_code\n",
    "                AND g.state_code = zip.state_code\n",
    "    WHERE   g.feature_class IN ('Populated Place')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21597076",
   "metadata": {},
   "source": [
    "## Publish to Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "(\n",
    "    geography_conformed\n",
    "    .write\n",
    "    .format('delta')\n",
    "    .mode('append')\n",
    "    .partitionBy('state_code')\n",
    "    .save(delta_path)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c32819",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "geography_delta = DeltaTable.forPath(spark, path=delta_path)\n",
    "geography_delta.toDF().count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
